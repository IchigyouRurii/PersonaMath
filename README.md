# PersonaMath: Enhancing Math Reasoning through Persona-Driven Data Augmentation

<p align="center" width="100%">
<a ><img src="images/personamath.png" alt="personamath" style="width: 80%; align: middle; display: block; margin: auto;">
<img src="images/gsm8k.png" alt="gsm8k" style="width: 45%; display: block; margin: auto;">
<img src="images/math.png" alt="math" style="width: 45%; display: block; margin: auto;"></a>
</p>

## Comparing PersonaMath with the current advanced open-source LLMs.


| Model               | GSM8k Pass@1 | MATH Pass@1 |
|---------------------|--------------|-------------|
| LLaMA-2-7B          | 14.6         | 2.5         |
| LLaMA-3.1-8B          | 57.2         | 20.3         |
| Falcon-40B          | 19.6         | 2.5         |
| Baichuan-2-7B   | 24.5        | 5.6         |
| DeepSeek-V2-Lite   | 41.1        | 17.1         |
| LLaMA-2-13B         | 28.7         | 3.9         |
| Baichuan-2-13B   | 52.8        | 10.1         |
| GLM-4-9B        | 84.0         | 30.4         |
| LLaMA-2-34B         | 42.2         | 6.24        |
| LLaMA-3.1-70B          | 83.7         | 41.4         |
| Qwen2.5-7B             | 85.4         | 49.8          |
| WizardMath-7B       | 54.9         | 10.7        |
| LLaMA-2-70B         | 56.8         | 13.5        |
| WizardMath-13B      | 63.9         | 14.0        |
| MetaMath-7B         | 66.5    | 19.8    |
| MetaMath-13B        | 72.3     | 22.4    |
| MetaMath-Mistral-7B | 77.7    | 28.2   |
| MetaMath-Llemma-7B  | 69.2     | 30.0    |
| WizardMath-70B      | 81.6         | 22.7        |
| MetaMath-70B        | 82.3     | 26.6   |
| :rocket: **PersonaMath-LLaMA-2-7B**        | **68.7**     | **24.2**  |
| :rocket: **PersonaMath-LLaMA-2-13B**        | **78.6**     | **28.5**   |
| :rocket: **PersonaMath-LLaMA-3.1-8B**      | **76.6**     | **36.6**   |
| :rocket: **PersonaMath-Qwen2.5-7B**      | **84.3**     | **56.6**   |
